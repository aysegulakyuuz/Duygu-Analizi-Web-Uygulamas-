{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5fcac0b-fabf-4592-b318-aa0b3f77e0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 48836\n",
      "Feedback dataset size: 14\n",
      "Merged dataset size: 48850\n",
      "Merged dataset saved as 'merged_emotions_dataset.csv'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 1 at dim 1 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m     label_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encodings, label_tensor\n\u001b[1;32m---> 79\u001b[0m train_encodings, train_labels \u001b[38;5;241m=\u001b[39m preprocess_data(merged_texts, merged_labels)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Veriyi DataLoader'a çevir\u001b[39;00m\n\u001b[0;32m     82\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(train_encodings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], train_encodings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m], train_labels)\n",
      "Cell \u001b[1;32mIn[16], line 76\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(texts, labels)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_data\u001b[39m(texts, labels):\n\u001b[0;32m     75\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[38;5;28mlist\u001b[39m(texts), truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 76\u001b[0m     label_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encodings, label_tensor\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 1 at dim 1 (got 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Cihazı belirle\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Veriyi yükle ve hazırla\n",
    "dataset = load_dataset(\"go_emotions\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Geri bildirim veritabanı işlemleri\n",
    "DB_NAME = 'feedback.db'\n",
    "\n",
    "def load_feedback_data():\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT text, actual_emotion FROM feedback\")\n",
    "    rows = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return rows\n",
    "\n",
    "# Veriyi yükle\n",
    "feedback_data = load_feedback_data()\n",
    "feedback_texts = [row[0] for row in feedback_data]\n",
    "feedback_labels = [row[1] for row in feedback_data]\n",
    "\n",
    "# Orijinal veri kümesini al\n",
    "original_texts = dataset['train']['text'] + dataset['validation']['text']\n",
    "original_labels = dataset['train']['labels'] + dataset['validation']['labels']\n",
    "\n",
    "# Tüm veriyi birleştir\n",
    "merged_texts = original_texts + feedback_texts\n",
    "merged_labels = original_labels + feedback_labels\n",
    "\n",
    "# Veri bütünlüğünü kontrol et\n",
    "print(f\"Original dataset size: {len(original_texts)}\")\n",
    "print(f\"Feedback dataset size: {len(feedback_texts)}\")\n",
    "print(f\"Merged dataset size: {len(merged_texts)}\")\n",
    "\n",
    "if len(merged_texts) != len(merged_labels):\n",
    "    print(\"Data length mismatch detected. Fixing...\")\n",
    "    min_len = min(len(merged_texts), len(merged_labels))\n",
    "    merged_texts = merged_texts[:min_len]\n",
    "    merged_labels = merged_labels[:min_len]\n",
    "\n",
    "# Label mapping\n",
    "label_mapping = {\n",
    "    \"admiration\": 0, \"amusement\": 1, \"anger\": 2, \"annoyance\": 3, \"approval\": 4, \"caring\": 5,\n",
    "    \"confusion\": 6, \"curiosity\": 7, \"desire\": 8, \"disappointment\": 9, \"disapproval\": 10,\n",
    "    \"disgust\": 11, \"embarrassment\": 12, \"excitement\": 13, \"fear\": 14, \"gratitude\": 15,\n",
    "    \"grief\": 16, \"joy\": 17, \"love\": 18, \"nervousness\": 19, \"optimism\": 20, \"pride\": 21,\n",
    "    \"realization\": 22, \"relief\": 23, \"remorse\": 24, \"sadness\": 25, \"surprise\": 26, \"neutral\": 27\n",
    "}\n",
    "\n",
    "# Geri bildirim verisindeki etiketleri sayısal kodlara çevirme\n",
    "feedback_labels_numerical = [label_mapping.get(label, 27) for label in feedback_labels]\n",
    "\n",
    "# Tekrardan veri birleştirme (sayısal etiketlerle)\n",
    "merged_texts = original_texts + feedback_texts\n",
    "merged_labels = original_labels + feedback_labels_numerical\n",
    "\n",
    "# Veriyi CSV olarak kaydet\n",
    "df = pd.DataFrame({'text': merged_texts, 'emotion': merged_labels})\n",
    "df.to_csv(\"merged_emotions_dataset.csv\", index=False)\n",
    "print(\"Merged dataset saved as 'merged_emotions_dataset.csv'.\")\n",
    "\n",
    "# Modeli eğitmek için veriyi işleme\n",
    "def preprocess_data(texts, labels):\n",
    "    encodings = tokenizer(list(texts), truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "    label_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    return encodings, label_tensor\n",
    "\n",
    "train_encodings, train_labels = preprocess_data(merged_texts, merged_labels)\n",
    "\n",
    "# Veriyi DataLoader'a çevir\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Modeli yükle ve ayarla\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=len(label_mapping)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Model eğitimi\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion)\n",
    "\n",
    "# Modeli kaydet\n",
    "torch.save(model.state_dict(), \"enhanced_emotion_recognition_model.pth\")\n",
    "print(\"Model training and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47b7d4-5ff3-4149-9337-511d56888048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
