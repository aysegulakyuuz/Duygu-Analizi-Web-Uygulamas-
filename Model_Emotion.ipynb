{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9da94e0f-18dd-4a9d-a993-dfb5fdff141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: torch in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a12572-8a4c-41ba-9fc8-2349d420e535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4450e232-b08f-499d-a05e-0644bc23e223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Training dataset size: 5000\n",
      "Test dataset size: 1000\n"
     ]
    }
   ],
   "source": [
    "# Load the GoEmotions dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"go_emotions\")\n",
    "\n",
    "# Use a small subset of the dataset\n",
    "train_data = dataset[\"train\"].select(range(5000))  # 1000 samples for training\n",
    "test_data = dataset[\"test\"].select(range(1000))    # 200 samples for testing\n",
    "\n",
    "print(f\"Training dataset size: {len(train_data)}\")\n",
    "print(f\"Test dataset size: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d7d52c9-a610-4909-b4d0-98e3fe724211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preprocessed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset by extracting text and labels\n",
    "def preprocess_data(batch):\n",
    "    return {\"text\": batch[\"text\"], \"labels\": batch[\"labels\"]}\n",
    "\n",
    "# Apply preprocessing to training and testing datasets\n",
    "train_data = train_data.map(preprocess_data)\n",
    "test_data = test_data.map(preprocess_data)\n",
    "\n",
    "print(\"Dataset preprocessed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f6c9bf-c360-4cec-bbbf-71b278b80f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load DistilBERT tokenizer and model\n",
    "print(\"Loading model and tokenizer...\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=28  # Number of emotion labels in GoEmotions dataset\n",
    ")\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c6ee50-0680-4f3e-86e5-5d13518fdfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preprocessed for single-label classification!\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset by extracting text and the first label (single-label classification)\n",
    "def preprocess_data(batch):\n",
    "    # Select only the first label for each sample (multi-label to single-label)\n",
    "    return {\"text\": batch[\"text\"], \"labels\": batch[\"labels\"][0] if len(batch[\"labels\"]) > 0 else 0}\n",
    "\n",
    "# Apply preprocessing to training and testing datasets\n",
    "train_data = train_data.map(preprocess_data)\n",
    "test_data = test_data.map(preprocess_data)\n",
    "\n",
    "print(\"Dataset preprocessed for single-label classification!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f763bab-df29-45da-afdd-22b54390358a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets tokenized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_data(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "# Apply tokenization to training and testing datasets\n",
    "train_data = train_data.map(tokenize_data, batched=True)\n",
    "test_data = test_data.map(tokenize_data, batched=True)\n",
    "\n",
    "print(\"Datasets tokenized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b623a556-5683-4943-acdf-13eef5f22eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets converted to PyTorch format!\n"
     ]
    }
   ],
   "source": [
    "# Convert datasets to PyTorch format\n",
    "train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "print(\"Datasets converted to PyTorch format!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b10d16-fd0b-4563-bcd5-96b33330bb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aysegul\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.3)\n",
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]\n",
    "import accelerate\n",
    "print(accelerate.__version__)\n",
    "!pip install accelerate>=0.26.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "310c3240-6dc1-4ff9-80ff-81a3a538bef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import accelerate\n",
    "print(accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfdfae3b-444b-4b2f-a21e-73df96ce9d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aysegul\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aysegul\\AppData\\Local\\Temp\\ipykernel_21704\\4055551088.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 23:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.837700</td>\n",
       "      <td>1.848366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.473700</td>\n",
       "      <td>1.690726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.012200</td>\n",
       "      <td>1.698148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1875, training_loss=1.67690882136027, metrics={'train_runtime': 1400.9395, 'train_samples_per_second': 10.707, 'train_steps_per_second': 1.338, 'total_flos': 194494326729984.0, 'train_loss': 1.67690882136027, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",             # Output directory for model checkpoints\n",
    "    evaluation_strategy=\"epoch\",       # Evaluate after each epoch\n",
    "    num_train_epochs=3,                # Train for 1 epoch (adjust if needed)\n",
    "    per_device_train_batch_size=8,     # Batch size per device\n",
    "    save_total_limit=1,                # Keep only the most recent checkpoint\n",
    "    logging_dir=\"./logs\",              # Directory for logs\n",
    "    logging_steps=10,    # Log every 10 steps\n",
    "    learning_rate=3e-5 \n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                       # The model to train\n",
    "    args=training_args,                # Training arguments\n",
    "    train_dataset=train_data,          # Training dataset\n",
    "    eval_dataset=test_data,            # Evaluation dataset\n",
    "    tokenizer=tokenizer                # Tokenizer for preprocessing\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting model training...\")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1fa6559-8f22-4c45-9d92-0f50a6c22a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a custom metric function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    accuracy = accuracy_score(labels, predictions.numpy())\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de8b9c15-917b-4284-95d3-7e41a88841b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aysegul\\AppData\\Local\\Temp\\ipykernel_21704\\96442585.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics  # Add custom metric function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96a00afa-df46-44c9-97da-235d4f5d1b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.698148250579834\n",
      "Accuracy: 0.517\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "print(\"Evaluating the model...\")\n",
    "results = trainer.evaluate()\n",
    "print(f\"Validation Loss: {results['eval_loss']}\")\n",
    "print(f\"Accuracy: {results['eval_accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb9521b3-ecef-4929-979a-c892c5e966dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion labels: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "emotions = dataset[\"train\"].features[\"labels\"].feature.names\n",
    "print(\"Emotion labels:\", emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac8a5655-2827-4b39-8387-ca2126df1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to get meaningful labels\n",
    "def predict_emotion(texts):\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        prediction = classifier(text)[0]  # Get the top prediction\n",
    "        label_index = int(prediction[\"label\"].split(\"_\")[-1])  # Extract numeric label index\n",
    "        emotion = emotions[label_index]  # Map to the emotion name\n",
    "        results.append(f\"Text: '{text}' -> Predicted Emotion: {emotion}, Confidence: {prediction['score']:.2f}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95d9dc81-ab73-4655-9e8e-d1204d6142ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "SafetensorError",
     "evalue": "Error while serializing: IoError(Os { code: 1224, kind: Uncategorized, message: \"The requested operation cannot be performed on a file with a user-mapped section open.\" })",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSafetensorError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the trained model and tokenizer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./emotion_recognition_modell\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./emotion_recognition_modell\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel and tokenizer saved successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:2980\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[1;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[0;32m   2975\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m   2977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[0;32m   2978\u001b[0m     \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[0;32m   2979\u001b[0m     \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[1;32m-> 2980\u001b[0m     safe_save_file(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file), metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m   2981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2982\u001b[0m     save_function(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\safetensors\\torch.py:286\u001b[0m, in \u001b[0;36msave_file\u001b[1;34m(tensors, filename, metadata)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[0;32m    256\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[0;32m    257\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    258\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m ):\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     serialize_file(_flatten(tensors), filename, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "\u001b[1;31mSafetensorError\u001b[0m: Error while serializing: IoError(Os { code: 1224, kind: Uncategorized, message: \"The requested operation cannot be performed on a file with a user-mapped section open.\" })"
     ]
    }
   ],
   "source": [
    "# Save the trained model and tokenizer\n",
    "model.save_pretrained(\"./emotion_recognition_modell\")\n",
    "tokenizer.save_pretrained(\"./emotion_recognition_modell\")\n",
    "\n",
    "print(\"Model and tokenizer saved successfully!\")\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the trained model for inference\n",
    "classifier = pipeline(\"text-classification\", model=\"./emotion_recognition_modell\", tokenizer=\"./emotion_recognition_modell\")\n",
    "\n",
    "# Test with example sentences\n",
    "print(classifier(\"I am so happy today!\"))  # Positive emotion\n",
    "print(classifier(\"I feel really sad and down.\"))  # Negative emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "196fb23b-3671-42c2-97a9-201e17a7ae1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'I am so happy today!' -> Predicted Emotion: joy\n",
      "Text: 'I feel really sad and down.' -> Predicted Emotion: sadness\n"
     ]
    }
   ],
   "source": [
    "# Load the GoEmotions label names\n",
    "emotions = dataset[\"train\"].features[\"labels\"].feature.names\n",
    "\n",
    "# Map the model output to emotion labels\n",
    "example_1 = classifier(\"I am so happy today!\")[0]\n",
    "example_1_label = emotions[int(example_1[\"label\"].split(\"_\")[-1])]\n",
    "print(f\"Text: 'I am so happy today!' -> Predicted Emotion: {example_1_label}\")\n",
    "\n",
    "example_2 = classifier(\"I feel really sad and down.\")[0]\n",
    "example_2_label = emotions[int(example_2[\"label\"].split(\"_\")[-1])]\n",
    "print(f\"Text: 'I feel really sad and down.' -> Predicted Emotion: {example_2_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f572be4-a414-4c93-b9f4-a6ca9ce8b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier(\"This is the best day of my life!\"))\n",
    "print(classifier(\"I am feeling very anxious and nervous.\"))\n",
    "print(classifier(\"What a boring and disappointing event.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "567a0856-3e76-4ee0-8851-dea87dc86aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I am incredibly proud of what I've accomplished. -> Predicted Emotion: admiration, Confidence: 0.92\n",
      "Text: This makes me feel so angry and frustrated. -> Predicted Emotion: anger, Confidence: 0.22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def classify_and_print(text, emotions, classifier):\n",
    "    result = classifier(text)[0] \n",
    "    label_index = int(result['label'].split('_')[-1])  # 'LABEL_0' -> 0\n",
    "    emotion = emotions[label_index]  \n",
    "    print(f\"Text: {text} -> Predicted Emotion: {emotion}, Confidence: {result['score']:.2f}\")\n",
    "\n",
    "\n",
    "emotions = dataset[\"train\"].features[\"labels\"].feature.names\n",
    "\n",
    "classify_and_print(\"I am incredibly proud of what I've accomplished.\", emotions, classifier)\n",
    "classify_and_print(\"This makes me feel so angry and frustrated.\", emotions, classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85242661-0953-4be3-b339-5d98b953558a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I am so grateful for all the support I've received! -> Predicted Emotion: gratitude, Confidence: 0.79\n",
      "Text: This is absolutely the worst day of my life. -> Predicted Emotion: disappointment, Confidence: 0.17\n",
      "Text: Wow, I can't stop laughing at this hilarious joke! -> Predicted Emotion: amusement, Confidence: 0.60\n",
      "Text: I feel so calm and relaxed when I'm by the sea. -> Predicted Emotion: caring, Confidence: 0.17\n",
      "Text: It's infuriating how people can be so inconsiderate! -> Predicted Emotion: anger, Confidence: 0.32\n",
      "Text: Today was one of the most exciting days of my life. I got to meet my favorite author, \n",
      "    and she even signed my book! It feels like a dream come true. I'm so thrilled and inspired \n",
      "    to start writing again after talking to her. -> Predicted Emotion: admiration, Confidence: 0.55\n",
      "Text: Life has been quite challenging lately. Every time I think I've made progress, another \n",
      "    obstacle appears. Sometimes, I wonder if things will ever get better. It's exhausting to \n",
      "    keep trying and failing, but I guess I have no choice but to move forward. -> Predicted Emotion: approval, Confidence: 0.10\n",
      "Text: I woke up early this morning, made a cup of coffee, and sat on the balcony to watch the sunrise. \n",
      "    The world felt so peaceful, and I couldn’t help but smile. These quiet moments remind me of how beautiful \n",
      "    life can be, even in its simplest forms. -> Predicted Emotion: admiration, Confidence: 0.62\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences_and_paragraphs = [\n",
    "    \"I am so grateful for all the support I've received!\",\n",
    "    \"This is absolutely the worst day of my life.\",\n",
    "    \"Wow, I can't stop laughing at this hilarious joke!\",\n",
    "    \"I feel so calm and relaxed when I'm by the sea.\",\n",
    "    \"It's infuriating how people can be so inconsiderate!\",\n",
    "    \"\"\"Today was one of the most exciting days of my life. I got to meet my favorite author, \n",
    "    and she even signed my book! It feels like a dream come true. I'm so thrilled and inspired \n",
    "    to start writing again after talking to her.\"\"\",\n",
    "    \"\"\"Life has been quite challenging lately. Every time I think I've made progress, another \n",
    "    obstacle appears. Sometimes, I wonder if things will ever get better. It's exhausting to \n",
    "    keep trying and failing, but I guess I have no choice but to move forward.\"\"\",\n",
    "    \"\"\"I woke up early this morning, made a cup of coffee, and sat on the balcony to watch the sunrise. \n",
    "    The world felt so peaceful, and I couldn’t help but smile. These quiet moments remind me of how beautiful \n",
    "    life can be, even in its simplest forms.\"\"\"\n",
    "]\n",
    "\n",
    "\n",
    "for text in sentences_and_paragraphs:\n",
    "    classify_and_print(text, emotions, classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c1e611f-4027-462d-a9fc-2f10cc1344df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I can't believe how kind everyone has been to me today. -> Predicted Emotion: surprise, Confidence: 0.28\n",
      "Text: Why does everything seem to go wrong at the worst possible time? -> Predicted Emotion: curiosity, Confidence: 0.48\n",
      "Text: I’m bursting with joy after hearing this wonderful news! -> Predicted Emotion: admiration, Confidence: 0.50\n",
      "Text: This situation is making me more frustrated than I’ve ever been. -> Predicted Emotion: annoyance, Confidence: 0.17\n",
      "Text: I feel so incredibly lucky to have such supportive friends. -> Predicted Emotion: admiration, Confidence: 0.25\n",
      "Text: The way they handled that issue was so unprofessional, I’m shocked! -> Predicted Emotion: surprise, Confidence: 0.20\n",
      "Text: It's such a beautiful day; I feel like everything is perfect right now. -> Predicted Emotion: admiration, Confidence: 0.93\n",
      "Text: I can’t stop crying because this memory is so emotional for me. -> Predicted Emotion: sadness, Confidence: 0.35\n"
     ]
    }
   ],
   "source": [
    "# Example sentences\n",
    "classify_and_print(\"I can't believe how kind everyone has been to me today.\", emotions, classifier)\n",
    "classify_and_print(\"Why does everything seem to go wrong at the worst possible time?\", emotions, classifier)\n",
    "classify_and_print(\"I’m bursting with joy after hearing this wonderful news!\", emotions, classifier)\n",
    "classify_and_print(\"This situation is making me more frustrated than I’ve ever been.\", emotions, classifier)\n",
    "classify_and_print(\"I feel so incredibly lucky to have such supportive friends.\", emotions, classifier)\n",
    "classify_and_print(\"The way they handled that issue was so unprofessional, I’m shocked!\", emotions, classifier)\n",
    "classify_and_print(\"It's such a beautiful day; I feel like everything is perfect right now.\", emotions, classifier)\n",
    "classify_and_print(\"I can’t stop crying because this memory is so emotional for me.\", emotions, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd405395-e7da-4c54-adaf-a15a207ebe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: After a long and tiring journey, I finally reached the summit of the mountain. \n",
      "The view was breathtaking, and all the effort felt completely worth it. Standing there, I felt \n",
      "an overwhelming sense of accomplishment and peace. -> Predicted Emotion: admiration, Confidence: 0.77\n",
      "Text: This has been the most disappointing project I’ve ever worked on. \n",
      "No one met their deadlines, and the result didn’t even come close to what we expected. \n",
      "It’s hard not to feel let down after putting in so much effort. -> Predicted Emotion: disappointment, Confidence: 0.32\n",
      "Text: Last night, I had the best dinner with my family. We laughed, shared stories, \n",
      "and simply enjoyed each other's company. It reminded me how precious these moments are \n",
      "and how grateful I am for my loved ones. -> Predicted Emotion: joy, Confidence: 0.39\n",
      "Text: Sometimes, I feel like the weight of the world is on my shoulders. \n",
      "Between work, studies, and personal responsibilities, it’s hard to find a moment to breathe. \n",
      "But deep down, I know I’ll get through it all, even if it feels overwhelming now. -> Predicted Emotion: approval, Confidence: 0.16\n",
      "Text: Yesterday, I got an unexpected letter from an old friend. Reading it brought back so \n",
      "many happy memories, and it felt like no time had passed since we last spoke. It’s amazing how \n",
      "some connections stay strong no matter how much time goes by. -> Predicted Emotion: admiration, Confidence: 0.71\n",
      "Text: Spending time at the beach this weekend was pure bliss. The sound of the waves, \n",
      "the warmth of the sun, and the cool ocean breeze made me feel so relaxed and content. \n",
      "I wish I could stay there forever. -> Predicted Emotion: desire, Confidence: 0.39\n",
      "Text: The announcement today left me speechless. I didn’t think such a big change \n",
      "would happen so suddenly, and I’m still processing it. It’s hard to say if I feel more excited \n",
      "or anxious about what’s coming next. -> Predicted Emotion: surprise, Confidence: 0.23\n",
      "Text: I’ve been working so hard on this project, and finally seeing it come together feels amazing. \n",
      "Every late night and tough decision has paid off, and I’m incredibly proud of what I’ve accomplished. -> Predicted Emotion: admiration, Confidence: 0.93\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example paragraphs\n",
    "classify_and_print(\"\"\"After a long and tiring journey, I finally reached the summit of the mountain. \n",
    "The view was breathtaking, and all the effort felt completely worth it. Standing there, I felt \n",
    "an overwhelming sense of accomplishment and peace.\"\"\", emotions, classifier)\n",
    "\n",
    "classify_and_print(\"\"\"This has been the most disappointing project I’ve ever worked on. \n",
    "No one met their deadlines, and the result didn’t even come close to what we expected. \n",
    "It’s hard not to feel let down after putting in so much effort.\"\"\", emotions, classifier)\n",
    "\n",
    "classify_and_print(\"\"\"Last night, I had the best dinner with my family. We laughed, shared stories, \n",
    "and simply enjoyed each other's company. It reminded me how precious these moments are \n",
    "and how grateful I am for my loved ones.\"\"\", emotions, classifier)\n",
    "\n",
    "classify_and_print(\"\"\"Sometimes, I feel like the weight of the world is on my shoulders. \n",
    "Between work, studies, and personal responsibilities, it’s hard to find a moment to breathe. \n",
    "But deep down, I know I’ll get through it all, even if it feels overwhelming now.\"\"\", emotions, classifier)\n",
    "\n",
    "classify_and_print(\"\"\"Yesterday, I got an unexpected letter from an old friend. Reading it brought back so \n",
    "many happy memories, and it felt like no time had passed since we last spoke. It’s amazing how \n",
    "some connections stay strong no matter how much time goes by.\"\"\", emotions, classifier)\n",
    "\n",
    "classify_and_print(\"\"\"Spending time at the beach this weekend was pure bliss. The sound of the waves, \n",
    "the warmth of the sun, and the cool ocean breeze made me feel so relaxed and content. \n",
    "I wish I could stay there forever.\"\"\", emotions, classifier)\n",
    "\n",
    "classify_and_print(\"\"\"The announcement today left me speechless. I didn’t think such a big change \n",
    "would happen so suddenly, and I’m still processing it. It’s hard to say if I feel more excited \n",
    "or anxious about what’s coming next.\"\"\", emotions, classifier)\n",
    "\n",
    "classify_and_print(\"\"\"I’ve been working so hard on this project, and finally seeing it come together feels amazing. \n",
    "Every late night and tough decision has paid off, and I’m incredibly proud of what I’ve accomplished.\"\"\", emotions, classifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3a47e-dbf7-4d93-bc3b-aad06b4d7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35906e86-d75a-479d-8ae1-be3304fc9051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a06e506-12fb-4ee5-b5ea-b99243991e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
